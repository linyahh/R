---
title: "Text Visualisation"
description: |
  Text Visualisation with R.
author:
  - name: Linya Huang
    url: https://www.linkedin.com/in/linya-huang/
date: 07-11-2021
output:
  distill::distill_article:
    toc: true
    toc_depth: 6
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.retina = 3,
  echo = TRUE,
                      eval = TRUE,
                      message = FALSE,
                      warning=FALSE)
```

# Import packages and data

```{r}
packages= c('tidytext','widyr','wordcloud','DT',
            'ggwordcloud','textplot','lubridate',
            'hms','tidyverse','tidygraph','ggraph','igraph')

for(p in packages){
  if(!require(p,character.only= T)){
    install.packages(p)
    }
  library(p, character.only = T)
}
```



```{r}

news20<-"data/20news/"

read_folder <- function(infolder) {
  tibble(file=dir(infolder,
                  full.names = TRUE)) %>%
    mutate(text= map(file,
                     read_lines)) %>%
    transmute(id=basename(file),
              text) %>%
    unnest(text)
}
```


```{r}
raw_text<- tibble(folder=
                    dir(news20,
                        full.names = TRUE))%>%
  mutate(folder_out=map(folder,
                        read_folder)) %>%
  unnest(cols=c(folder_out))%>%
  transmute(newsgroup=basename(folder),
            id,text)
write_rds(raw_text,"data/rds/news20.rds")
```

# Initial EDA

```{r}
raw_text%>%
  group_by(newsgroup)%>%
  summarize(messages=n_distinct(id))%>%
  ggplot(aes(messages,newsgroup))+
  geom_col(fill="lightblue")+
  labs(y=NULL)
```
# Clean Text Data

remove headers 
```{r}
cleaned_text <- raw_text %>%
  group_by(newsgroup, id) %>%
  filter(cumsum(text=="")>0,
         cumsum(str_detect(
           text,"^--"))==0) %>%
           ungroup()


```

```{r}
cleaned_text <- cleaned_text %>%
  filter(str_detect(text, "^[^>]+[A-Za-z\\d]")
         | text == "",
        !str_detect(text,
                     "writes(:|\\.\\.\\.)$"),
         !str_detect(text,
                     "^In article <"))
         
```

# Tokenization

```{r}
usenet_words <- cleaned_text %>% 
  unnest_tokens(word,text) %>% 
  filter(str_detect(word,"[a-z']$"),
         !word %in% stop_words$word)
```

# Visualising words in newsgroups


```{r}
usenet_words %>%
  count(word,sort=TRUE)

words_by_newsgroup <- usenet_words %>% 
  count(newsgroup,word,sort=TRUE) %>% 
  ungroup()
head(words_by_newsgroup)

```
```{r}

wordcloud(words_by_newsgroup$word,
          words_by_newsgroup$n,
          max.words = 300)

#DT can be added to shiny for interactive selection

```

```{r}
set.seed(1234)

words_by_newsgroup %>% 
  filter(n>0) %>% 
  ggplot(aes(label=word,
             size=n))+
  geom_text_wordcloud()+
  theme_minimal()+
  facet_wrap(~newsgroup)
```

# Computing tf_idf
```{r}
tf_idf <- words_by_newsgroup %>% 
  bind_tf_idf(word,newsgroup,n) %>% 
  arrange(desc(tf_idf))

```


## insert interactive table using __DT__
```{r}
DT::datatable(tf_idf, filter ="top") %>% 
  formatRound(columns= c('tf','idf','tf_idf'),
              digits=3) %>% 
  formatStyle(0,
              target = 'row',
              lineHeight='25%')
```

```{r}
tf_idf %>% 
  filter(str_detect(newsgroup,"^sci\\.")) %>% 
  group_by(newsgroup) %>% 
  slice_max(tf_idf,
            n=12) %>% 
  ungroup() %>% 
  mutate(word = reorder(word,
                         tf_idf)) %>% 
  ggplot(aes(tf_idf,
             word,
             fill=newsgroup))+
  geom_col(show.legend = FALSE)+
  facet_wrap(~newsgroup,
             scales="free")+
  labs(x="tf-idf",
       y=NULL)
```
```{r}
newsgroup_cors <-words_by_newsgroup %>% 
  pairwise_cor(newsgroup,
               word,
               n,
               sort=TRUE)
head(newsgroup_cors)

```

# visualize text network



```{r}
set.seed(1234)


newsgroup_cors %>% 
  filter(correlation> 0.025) %>% 
  graph_from_data_frame() %>% 
  ggraph(layout = "fr") + 
  geom_edge_link(aes(alpha=correlation,
                     width= correlation))+
  geom_node_point(size=6,
                  color="lightblue")+
  geom_node_text(aes(label=name),
                 color="red",
                 repel=TRUE)+
  theme_void()
            
```

# Bigram

```{r}
bigrams <- cleaned_text %>% 
  unnest_tokens(bigram,
                text,
                token="ngrams",
                n=2)


bigrams_count <- bigrams %>% 
  filter(bigram !="NA") %>% 
  count(bigram,sort=TRUE)

# Cleaning bigram

bigrams_seperated <- bigrams %>% 
  filter(bigram !="NA") %>% 
  separate(bigram, c("word1","word2"),
           sep=" ")


bigram_filtered<- bigrams_seperated %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word2 %in% stop_words$word)
head(bigram_filtered)
```
```{r}

bigrams_count<- bigram_filtered %>% 
  count(word1,word2,sort=TRUE)

bigram_graph<-bigrams_count %>% 
  filter(n>3) %>% 
  graph_from_data_frame()
bigram_graph
```
```{r}
set.seed(1234)


ggraph(bigram_graph, layout = 'fr')+
  geom_edge_link()+
  geom_node_point()+
  geom_node_text(aes(label=name),
                 vjust=1,
                 hjust=1)


```

```{r}
set.seed(1234)

```

